# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UeB-H0puvJOY0tpaD09gPECgrzbCWcYr
"""

import random
import torch
import time
import glob, os
from features import get_gdata
from features import get_routability
from features import node_features
from features import edge_ex
from features import finout
from features import finout_blks
from features import vinout_blks
from features import add_metis
from features import totuple
from preper import create_dataset
from preper import merge_node_features
from GAT import GAT
from test_train import test1
from test_train import train1


# -----------------------------------------------get the feautes--------------------------------------------------
graph_features=[]
blks_size=[]
edge_size=[]
circuit_names=[]
routability=[]
nodes_blktype=[]
edges=[]
fin=[]
fout=[]
file_address = "/home/saba/DL/SmartVPR-master/pack-res/dataset/blif-res/stratixiv_arch.timing.xml"

blilf = ["alu4.blif", "clock_aliases.blif",  "elliptic.blif",  "pdc.blif", "tseng.blif","apex4.blif", "des.blif", "ex1010.blif", "s38417.blif","bigkey.blif",  "diffeq.blif", "frisc.blif", "s38584.1.blif","clma.blif", "dsip.blif", "misex3.blif","seq.blif"]

cw=[250,300]
for ch in cw:
#  print(ch)
 for name in range(len(blif)):
# for i in range(1,11):
    dt=get_gdata(file_address + blif[name] + "/" + ch + "/features/graph_features.txt")
    a,b,c,d=get_features1(dt)
    graph_features.append(a)
    blks_size.append(b)
    edge_size.append(c)
    circuit_names.append(d)
    routability.append(get_routability(file_address + + blif[name] + "/" + ch + "/features/routability.txt"))
    nodes_blktype.append(node_features(file_address + + blif[name] + "/" + ch + "/features/node_f-blktype.txt"))
    edges.append(edge_ex(file_address + + blif[name] + "/" + ch + "/features/edges.txt"))
    h,z=finout(file_address + + blif[name] + "/" + ch + "/features/nodef-finfout.txt")
    fin.append(h)
    fout.append(z)

in_blks , out_blks = finout_blks()

vin_blks , vout_blks = vinout_blks()

edge_f=[]
metis_times=[]
for i in range(len(edges)):
  t1 = time.time()
  f1=add_metis(list(totuple(edges[i])), 2)
  t2 = time.time()
  # print(i,t2-t1)
  f2=add_metis(list(totuple(edges[i])), 5)
  t3 = time.time()
  # print(i,t3-t2)
  f3=add_metis(list(totuple(edges[i])), 10)
  t4 = time.time()
  # print(i,t4-t3)
  # f4=add_metis(list(totuple(edges[i])), 50)
  # t5 = time.time()
  # print(i,t5-t4)
  f5=add_metis(list(totuple(edges[i])), 100)
  t6 = time.time()
  # print(i,t6-t5)
  f6=add_metis(list(totuple(edges[i])), 1000)
  t7 = time.time()
  # print(i,t7-t6)
  f7=add_metis(list(totuple(edges[i])), int(len(edges)/5))
  t8 = time.time()
  # print(i,t8-t7)
  f8=add_metis(list(totuple(edges[i])), int(len(edges)/10))
  t9 = time.time()
  metis_times.append(i,t9-t1)
  # print(i,i,t9-t1)
  # f9=add_metis(list(totuple(edges[i])), int(len(nodes)/100))

  edge_f.append(torch.stack((torch.tensor(f1),torch.tensor(f2),torch.tensor(f3),torch.tensor(f5),torch.tensor(f6),torch.tensor(f7),
               torch.tensor(f8)),dim=0))
  

node_f = merge_node_features(nodes_blktype,fin,fout,in_blks,out_blks,vin_blks,vout_blks)
dataset=create_dataset(node_f,edges,edge_f,routability)
batch = torch_geometric.data.Batch().from_data_list(dataset)
print("Number of graphs:",batch.num_graphs)
print("Graph at index 0:",batch[0])
# t1=time.now()
torch.manual_seed(12345)
sz = len(dataset)
indices = [i for i in range(sz)]
# random.shuffle(indices)
torch.manual_seed(100)
# test_indices=indices[:int(sz):]
# train_indices = indices[0]
train_indices = indices[:int(sz * 3 / 4)] #train o testa ro index ha ro joda kardim
test_indices = indices[int(sz * 3/ 4):]
print(sz, train_indices, test_indices)
    

gf = graph_features
optimizer = torch.optim.Adam(GAT.parameters(), lr=0.01)
criterion = torch.nn.BCELoss()
# test_acc = test1(test_indices, batch, gf)

# print(test1(test_indices, batch, gf))
# print(f'Epoch: {epoch:03d}, Test Acc: {test_acc:.4f},  Time: {running_secs}')
for epoch in range(1, 171):
    start = time.times()
    # train(train_indices, batch, gf)
    train_acc = train1(train_indices, batch, gf)
    test_acc = test1(test_indices, batch, gf)

    running_secs = time.times() - start
    # print(f'Epoch: {epoch:03d}, Test Acc: {test_acc:.4f},  Time: {running_secs}')
    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f} , Test Acc: {test_acc:.4f},  Time: {running_secs}')